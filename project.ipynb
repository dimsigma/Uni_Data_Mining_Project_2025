{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba01f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import Birch\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e86116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read CSV file & Future Formatting\n",
    "df_data = pd.read_csv(\"data.csv\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "\n",
    "# Identify unnecessary and target columns\n",
    "DROP_LABELS = [\"Flow ID\", \"Src IP\", \"Src Port\", \"Dst IP\", \"Dst Port\", \"Timestamp\"]\n",
    "TARGET_LABELS = [\"Label\", \"Traffic Type\", \"Traffic Subtype\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110b8a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data introduction\n",
    "# Sampling\n",
    "def sampling(df: pd.DataFrame, cap: int, rate: float, notext=False) -> pd.DataFrame:\n",
    "    if notext == False:\n",
    "        print(\"Dataset before sampling has\", df.shape[0], \"rows and\", df.shape[1], \"columns\")\n",
    "        print(\"Sampling ...\")\n",
    "\n",
    "    if cap != 0:\n",
    "        subtype_counts = df[\"Traffic Subtype\"].value_counts()  # All the traffic subtypes\n",
    "        subtypes_sampling = subtype_counts[subtype_counts > cap].index    # All the traffic subtypes with over 10000 rows\n",
    "        subtypes_nosampling = subtype_counts[subtype_counts <= cap].index # All the traffic subtypes with under 10000 rows\n",
    "        \n",
    "        df_sampling = df[df[\"Traffic Subtype\"].isin(subtypes_sampling)]   # DataFrame with all the oversized traffic subtypes\n",
    "        df_sampled = df_sampling.sample(frac=rate)  # Sampled DataFrame for oversized traffic types\n",
    "        df_notsampled = df[df[\"Traffic Subtype\"].isin(subtypes_nosampling)]   # DataFrame for rest of traffic types\n",
    "        df_final =  pd.concat([df_sampled, df_notsampled], ignore_index=True)  # Final  partially sampled DataFrame\n",
    "\n",
    "    else:\n",
    "        df_final = df.sample(frac=rate)\n",
    "        \n",
    "    if notext == False:\n",
    "        print(\"Dataset after sampling has\", df_final.shape[0], \"rows and\", df_final.shape[1], \"columns\")\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "# Drop unnecessary data\n",
    "def drop_unnecessary(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    print(\"Dataset before removing unnecessary data has\", df.shape[0], \"rows and\", df.shape[1], \"columns\")\n",
    "    print(\"Removing unnecessary data ...\")\n",
    "    df_final =  df.drop(columns=DROP_LABELS)\n",
    "    print(\"Dataset after removing unnecessary data has\", df_final.shape[0], \"rows and\", df_final.shape[1], \"columns\")\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "# Data presentation\n",
    "def present(df: pd.DataFrame):\n",
    "    display(df.head())\n",
    "    display(df.tail())\n",
    "    display(df.describe().T)\n",
    "    display(df.groupby(TARGET_LABELS).size().reset_index(name=\"Counts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5278f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Correlation, target correlation and intresting columns\n",
    "LABEL_MAPPER = {\"Malicious\": 1, \"Benign\": 0}\n",
    "TYPES_MAPPER = {\"Audio\": 0, \"Background\": 1, \"Text\": 2, \"Video\": 3, \"Bruteforce\": 4, \"DoS\": 5, \"Information Gathering\": 6, \"Mirai\": 7}\n",
    "\n",
    "def labels_to_numerical(df: pd.DataFrame, mapper: dict) -> pd.DataFrame:\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"Label\"] = df_copy[\"Label\"].map(mapper)\n",
    "    return df_copy\n",
    "\n",
    "def ttypes_to_numerical(df: pd.DataFrame, mapper: dict) -> pd.DataFrame:\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"Traffic Type\"] = df_copy[\"Traffic Type\"].map(mapper)\n",
    "    return df_copy\n",
    "\n",
    "def correlation(df_numerical: pd.DataFrame, target=False):\n",
    "    if target == True:\n",
    "        important_metrics_label = []\n",
    "        important_metrics_ttype = []\n",
    "        df_copy = df_numerical.copy()\n",
    "        cor = df_copy.corr(numeric_only=True).filter([\"Label\", \"Traffic Type\"])\n",
    "\n",
    "        for r in cor.index.tolist():\n",
    "            if abs(cor.at[r, \"Label\"]) > 0.1 and r != \"Traffic Type\":\n",
    "                important_metrics_label.append(r)\n",
    "                print(r, cor.at[r, \"Label\"])\n",
    "            if abs(cor.at[r, \"Traffic Type\"]) > 0.1 and r != \"Label\":\n",
    "                important_metrics_ttype.append(r)\n",
    "\n",
    "        print(len(important_metrics_label), \"Metrics with high correlation with Label\")\n",
    "        print(len(important_metrics_ttype), \"Metrics with high correlation with Traffic Type\")\n",
    "        return cor, important_metrics_label, important_metrics_ttype\n",
    "\n",
    "    else:\n",
    "        df_copy = df_numerical.copy()\n",
    "        return df_copy.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f80a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Visualization\n",
    "# Create heatmap from correlation Pandas Dataframe\n",
    "def heatmap(corr: pd.DataFrame, title: str) -> None:\n",
    "    print(\"Generating heatmap ...\")\n",
    "    plt.figure(figsize=(30, 20))\n",
    "    sns.heatmap(corr, cmap=\"coolwarm\", square=True)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Create boxplot diagram to showcase target differences\n",
    "def boxplot(df: pd.DataFrame, title: str, y_lim_bot: float, y_lim_top: float) -> None:\n",
    "    print(\"Generating boxplot ...\")\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    sns.boxplot(data=df)\n",
    "    plt.ylim((y_lim_bot, y_lim_top))\n",
    "    plt.xticks(rotation = 65, ha = \"right\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Create barplot to showcase certain values\n",
    "def barplot(x, y, title: str) -> None:\n",
    "    print(\"Generating barplot ...\")\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    sns.barplot(x=x, y=y)\n",
    "    plt.ylim((-1, 1))\n",
    "    plt.xticks(rotation = 65, ha = \"right\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True, axis=\"y\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b459662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dimensionality Reduction\n",
    "PCA_COLS = [\"PC1\", \"PC2\", \"PC3\", \"PC4\", \"PC5\", \"PC6\", \"PC7\", \"PC8\", \"PC9\", \"PC10\", \"PC11\", \"PC12\", \"PC13\", \"PC14\", \"PC15\"]\n",
    "\n",
    "def dim_reduction(df: pd.DataFrame, N: int, method: str) -> pd.DataFrame:\n",
    "    if method == \"PCA\":\n",
    "        scaler = StandardScaler()\n",
    "        df_scaled = scaler.fit_transform(df)\n",
    "        pca = PCA(n_components=N)\n",
    "        principal_components = pca.fit_transform(df_scaled)\n",
    "        df_final = pd.DataFrame(data=principal_components, columns=PCA_COLS[:N])\n",
    "        print(\"PCA METHOD --> Cumulative variance:\", pca.explained_variance_ratio_.cumsum()[-1])\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d028191",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clustering\n",
    "# BIRCH Algorithm\n",
    "def BIRCH_clustering(df: pd.DataFrame,) -> pd.DataFrame:\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df)\n",
    "    clusterer = Birch(n_clusters=None)\n",
    "    clusterer.fit(df_scaled)\n",
    "    df[\"Cluster\"] = clusterer.labels_\n",
    "    return df\n",
    "\n",
    "# HDBSCAN Algorithm\n",
    "def HDBSCAN_clustering(df: pd.DataFrame, minimum_cluster_size: int) -> pd.DataFrame:\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df)\n",
    "    clusterer = hdbscan.HDBSCAN(min_cluster_size=minimum_cluster_size, metric=\"euclidean\")\n",
    "    clusters = clusterer.fit_predict(df_scaled)\n",
    "    df[\"Cluster\"] = clusters\n",
    "    return df\n",
    "\n",
    "# Present HDBSCAN results\n",
    "def HDBSCAN_results(df: pd.DataFrame):\n",
    "    sns.countplot(x=\"HDBSCAN_Cluster\", data=df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d52b341",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initial sampling, remove excess metrics and duplicates in order to create plots in reasonable time, present data\n",
    "df = sampling(df_data, cap=10000, rate=0.05)\n",
    "df = drop_unnecessary(df)\n",
    "present(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8ce686",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Present distributions for all metrics for both Benign and Malicious labels\n",
    "ylim_top = 1.4 * 1e8\n",
    "ylim_bot = -0.1 * 1e8\n",
    "df_benign = df[df[\"Label\"] == \"Benign\"]\n",
    "df_malicious = df[df[\"Label\"] == \"Malicious\"]\n",
    "\n",
    "benign_list = [\"Audio\", \"Background\", \"Text\", \"Video\"]\n",
    "malicious_list = [\"Bruteforce\", \"DoS\", \"Information Gathering\", \"Mirai\"]\n",
    "\n",
    "for ttype in benign_list:\n",
    "    boxplot(df_benign[df_benign[\"Traffic Type\"] == ttype].drop(columns=TARGET_LABELS), \"Boxplot for traffic type: \" + ttype, ylim_bot, ylim_top)\n",
    "\n",
    "for ttype in malicious_list:\n",
    "    boxplot(df_malicious[df_malicious[\"Traffic Type\"] == ttype].drop(columns=TARGET_LABELS), \"Boxplot for traffic type: \" + ttype, ylim_bot, ylim_top)\n",
    "\n",
    "boxplot(df_benign.drop(columns=TARGET_LABELS), \"Boxplot for Benign\", ylim_bot, ylim_top)\n",
    "boxplot(df_malicious.drop(columns=TARGET_LABELS), \"Boxplot for Malicious\", ylim_bot, ylim_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60b00a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all data to numerical and compute correlations\n",
    "df_num = labels_to_numerical(df, LABEL_MAPPER)\n",
    "df_num = ttypes_to_numerical(df_num, TYPES_MAPPER)\n",
    "\n",
    "cor1 = correlation(df_num)\n",
    "cor2, important_metrics_label, important_metrics_ttype = correlation(df_num, target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b43693",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create heatmaps\n",
    "heatmap(cor1, \"Correlation between metrics\")\n",
    "heatmap(cor2, \"Correlation between metrics and target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba9cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Showcase top correlations\n",
    "df_important_metrics_label_count = cor2.filter(items=important_metrics_label, axis=\"index\").filter([\"Label\"]).sort_values(by=\"Label\")\n",
    "barplot(\n",
    "    df_important_metrics_label_count.index, df_important_metrics_label_count.values.reshape(len(df_important_metrics_label_count.index)),\n",
    "    \"Top metrics in terms of correlation with Label\"\n",
    ")\n",
    "\n",
    "df_important_metrics_ttype_count = cor2.filter(items=important_metrics_ttype, axis=\"index\").filter([\"Traffic Type\"]).sort_values(by=\"Traffic Type\")\n",
    "barplot(\n",
    "    df_important_metrics_ttype_count.index, df_important_metrics_ttype_count.values.reshape(len(df_important_metrics_ttype_count.index)),\n",
    "    \"Top metrics in terms of correlation with Traffic Type\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e64ba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DataFrames with metrics highly correlated with targets, dimension reduction\n",
    "DIM_TARGET = 10\n",
    "df_label = df_num[important_metrics_label]\n",
    "df_ttype = df_num[important_metrics_ttype]\n",
    "\n",
    "print(\"Target Label:\")\n",
    "df_labelDimReduction = dim_reduction(df_label.drop(columns=[\"Label\"]), DIM_TARGET, \"PCA\")\n",
    "df_labelDimReduction[\"Label\"] = df_label[\"Label\"]\n",
    "print(\"Target Traffic Type:\")\n",
    "df_ttypeDimReduction = dim_reduction(df_ttype.drop(columns=[\"Traffic Type\"]), DIM_TARGET, \"PCA\")\n",
    "df_ttypeDimReduction[\"Traffic Type\"] = df_ttype[\"Traffic Type\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517922ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sampling, Clustering with Kmeans, Clustering with BIRCH\n",
    "# Data reduction through sampling\n",
    "df_label_sampling = sampling(df_labelDimReduction, 0, 0.3, notext=True)\n",
    "df_ttype_sampling = sampling(df_ttypeDimReduction, 0, 0.3, notext=True)\n",
    "\n",
    "# Data reduction through BIRCH clustering\n",
    "df_label_BIRCH = BIRCH_clustering(df_labelDimReduction.drop(columns=[\"Label\"]))\n",
    "df_ttype_BIRCH = BIRCH_clustering(df_ttypeDimReduction.drop(columns=[\"Traffic Type\"]))\n",
    "\n",
    "# Data reduction through HDBSCAN clustering\n",
    "df_label_HDBSCAN = HDBSCAN_clustering(df_labelDimReduction.drop(columns=[\"Label\"]), 10)\n",
    "df_ttype_HDBSCAN = HDBSCAN_clustering(df_ttypeDimReduction.drop(columns=[\"Traffic Type\"]), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad0e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_label_BIRCH.groupby(\"Cluster\").size().reset_index(name=\"Counts\"))\n",
    "display(df_ttype_BIRCH.groupby(\"Cluster\").size().reset_index(name=\"Counts\"))\n",
    "display(df_label_HDBSCAN.groupby(\"Cluster\").size().reset_index(name=\"Counts\"))\n",
    "display(df_ttype_HDBSCAN.groupby(\"Cluster\").size().reset_index(name=\"Counts\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
